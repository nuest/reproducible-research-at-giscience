"","paper","year","authors","title","conceptual paper","reviewer 1","reviewer 2","input data","preprocessing","method/analysis/processing","computational environment","results","reviewer notes"
"1","12018","2018","Amores, David ; Vasardani, Maria ; Tanin, Egemen","Early Detection of Herding Behaviour during Emergency Evacuations","F","DN","FO","1","NA","1","0","1","DN: simulation data, open source tool > possible to make much more transparent!"
"2","22018","2018","Belussi, Alberto ; Carra, Damiano ; Migliorini, Sara ; Negri, Mauro ; Pelagatti, Giuseppe","What Makes Spatial Data Big? A Discussion on How to Partition Spatial Data","F","FO","MK","0","1","1","0","1","MK: I couldn't find a description of the comp. environm. Did I miss it?
Frank checked and agreed."
"3","32018","2018","Fogliaroni, Paolo ; Bucher, Dominik ; Jankovic, Nikola ; Giannopoulos, Ioannis","Intersections of Our World","F","MK","DN","0","1","1","0","1","DN: OSM data (whole planet), PostGIS, web application for exploring precomputed information > definetely could be made more reproducible! https://intersection.geo.tuwien.ac.at/# still functional!; software versions partly mentioned (PostGIS) but no code; polygons used for the cities to get the same results _with their web tool_ are missing

Decision: One of the two datasets (albeit the smaller one) is not recreatable data: 0;"
"4","42018","2018","Harvey, Francis","Considerations of Graphical Proximity and Geographical Nearness","F","CG","BH","0","NA","1","0","1","Borderline. Main aim is to propose a theory of geo-graphical nearness. Exploratory experiment, computational analysis of human-subject survey data, but no preprocessing step;

Experiment:
- ""Data collected for the study comes from an online survey developed with the software suite Lime Survey"". 
- ""[data] was analyzed using classical and Bayesian methods available in the open software package JASP"""
"5","52018","2018","Hu, Yingjie ; Janowicz, Krzysztof","An Empirical Study on the Names of Points of Interest and Their Changes with Geographic Distance","F","BH","CG","0","1","1","0","1","Mentioning of a python script that is not provided; formulas used documented in the text; statistical measures provided as result; data from YELP dataset - available for download, but metadata on time of download missing"
"6","62018","2018","Jeong, Myeong-Hun ; Yin, Junjun ; Wang, Shaowen","Outlier Detection and Comparison of Origin-Destination Flows Using Data Depth","F","BH","DN","0","0","0","0","1","BH: Data: taxi data from May-July 2014 in NY; unavailable / for other plots other taxi data dates are used; R is mentioned, but no code is provided; use of multiple cores mentioned - no further details provided; 

DN: TAZ data is described, but that's only partial; Dates are mentioned clearly, but no URL where to get the data; ""Hadoop with Pig, AWS and the Bridger supercomputer""... not good enough - ""link to the code is available upon request""; ""data cleaning process"" is mentioned = preprocessing;"
"7","72018","2018","Kattenbeck, Markus ; Nuhn, Eva ; Timpf, Sabine","Is Salience Robust? A Heterogeneity Analysis of Survey Ratings","F","CG","MK","1","1","1","0","1","- ""[Collected data] will be accessible via Data in Brief https://www.journals.elsevier.com/data-in-brief by the end of 2018"". I checked. No paper yet
- ""the first author of this paper collected data throughout his PhD [19]. ""
- ""A custom designed Android application facilitated the data collection in [19] and this application was reused for our study in Augsburg""
- ""PLS Path modeling as a statistical method and as an adequate means of assessing measurement invariance"""
"8","82018","2018","Krumpe, Filip","Labeling Points of Interest in Dynamic Maps using Disk Labels","F","MK","FO","1","2","2","0","1","FO: Not sure about the ""2""'s, difficult case because actual analysis code is not provided, but Github repository has the library
MK: I am fine with the 2s but I couldn't find a description for the computational environment used to compute the table. So I gave it a 0
Frank checked and agreed"
"9","92018","2018","Lafia, Sara ; Turner, Andrew ; Kuhn, Werner","Improving Discovery of Open Civic Data","F","BH","DN","0","NA","1","0","1","DN: I think there is data analysis happening here (Figure 7 & 8)!

BH: I tried a quick assessment; requires a second opinion

Analsis of ArcGIS Hub query log data; onotology term expansion tool;  mentions triplestore but no versions; steps ""harvesting, validation, enrichment"" seem to be scripted; no identifiable preprocessing step;"
"10","102018","2018","Li, Yan ; Shekhar, Shashi","Local Co-location Pattern Detection: A Summary of Results","F","FO","CG","0","1","1","1","1","""The platform for the simulation was Microsoft .NET Framework 4.5 on a computer with Intel(R) Core(TM) i7-4770 3.40 GHz CPU and 32 GB RAM"""
"11","112018","2018","Méneroux, Yann ; Kanasugi, Hiroshi ; Saint Pierre, Guillaume ; Le Guilcher, Arnaud ; Mustière, Sébastien ; Shibasaki, Ryosuke ; Kato, Yugo","Detection and Localization of Traffic Signals with GPS Floating Car Data and Random Forest","F","DN","BH","0","1","1","1","1","DN: ""extract routable map from the national reference"" - is that redoable? But commercial floating car data; preprocessing described in text; processing algorithms cited and math given; hardware is described; R randomForest package mentioned but without version; BH: very strict to limit methods to 1 because of a missing verison of the R code - they do provide a reference to the package from the year 2002 but ok, that might not be enough. Agree on the data - also for OSM we would need more details"
"12","122018","2018","Murray, Alan T. ; Feng, Xin ; Shokoufandeh, Ali","Heterogeneous Skeleton for Summarizing Continuously Distributed Demand in a Region","F","DN","CG","0","NA","1","0","1","Only this: ""The models were implemented in the Python platform using arcpy, pysal and sympy libraries, amoung others, on a Windows 10 Enterprise server with an Intel Xeon E5-2650 v3 (2.3GHz) 64 bit CPU and 64 GB of RAM. ArcGIS was utilized for data creation, management, manipulation, analysis, and visualization""

DN: no versions given, no code; no mentioning where the study region is or comes from, or how the data was prepared for applying the described algorithm; no distinctive preprocessing step;"
"13","132018","2018","Niedermann, Benjamin ; Oehrlein, Johannes ; Lautenbach, Sven ; Haunert, Jan-Henrik","A Network Flow Model for the Analysis of Green Spaces in Urban Areas","F","FO","DN","1","1","1","1","1","DN: extensive text description of the algorithm/model, but no code; link to data source broken (works without the www, i.e. https://land.copernicus.eu/ - how stupid (not of the authors)), data source probably reliable; Software with versions and hardware described; one used software (Gurobi) is commercial/not open; http://www2.geoinfo.uni-bonn.de/urbanarea/ still works, and is useful!

Conflict FO/DN: the result visualisations are scripted, but we don't have access to the scripts or data;"
"14","142018","2018","Saha, Rudra Ranajee ; Hashem, Tanzima ; Shahriar, Tasmia ; Kulik, Lars","Continuous Obstructed Detour Queries","F","MK","BH","0","0","1","1","1","BH: paper is way too mathematical for me to understand. Regarding data: I do not know what original data they refer to and the data they generated do not seem to be available; preprocessing not necessary - or do you refer to the generation of random POIs, Markus?
MK: Regarding input data. There is some initial description but I agree this is not enough for 1, so I changed it to 0.
Regarding Preprocessing: To me, the sections 5.2 and 5.3 read like there is some preprocessing going on though I do not understand what exactly they are doing. How about changing it to 0? 1 is too much, I would agree with that.
DN: for me, the ""generate synthetic POIs"" in section 6 definetely falls into preprocessing; mention CPU/Memory, but no software/versions"
"15","152018","2018","Schito, Joram ; Wissen Hayek, Ulrike ; Raubal, Martin","Enhanced Multi Criteria Decision Analysis for Planning Power Transmission Lines","F","CG","FO","0","1","1","1","1","- ""we explore the utility of a Cluster Analysis in combination with a Principal Component Analysis and a Multivariate Analysis of Variance""

FO: ""we collected the appropriate data from publicly accessible data portals and stored them in a database"""
"16","162018","2018","Shashidharan, Ashwin ; Vatsavai, Ranga Raju ; Van Berkel, Derek B. ; Meentemeyer, Ross K.","FUTURES-AMR: Towards an Adaptive Mesh Refinement Framework for Geosimulations","F","BH","MK","0","0","1","1","1","BH: again, I do not see any specific preprocessing used?
MK: I think there is some preprocessing going in section 4.1.1 and further described in 4.2 (""...policies specified as input to the simulation [...] policies serve as refinement and coarsing criteria for a simulation to perform refinement.""). What do you think about that?
DN: Re. sections pointed out by MK: these steps part of the algorithm that is developed, and therefore IMO not preprocessing; what I would consider preprocessing is in section 5 the creation of the varying input resolutions used for the experiment, which is still a 0 with the given information; re. input data, the paper only mentions year and location, but not sensor, source etc.;"
"17","172018","2018","Yan, Bo ; Janowicz, Krzysztof ; Mai, Gengchen ; Zhu, Rui","xNet+SC: Classifying Places Based on Images by Incorporating Spatial Contexts","F","BH","FO","0","1","1","1","1","FO: very well described with sufficient information to replicate; however, I could not find any actual code or the exact input data (the images)

BH: images not recreatable"
"18","12016","2016","Cici Alexander, Lars Arge, Peder Klith Bøcher, Morten Revsbæk, Brody Sandel, Jens-Christian Svenning et al.","Computing River Floods Using Massive Terrain Data","F","DN","FO","2","1","1","1","1","data link https://gst.dk/emner/frie-data/hvilke-data-er-omfattet/hvilke-data-er-frie/dhm-danmarks-hoejdemodel/ is broken, but certainly was at the time - it is not a 3 though; SRTM grid data and MODIS can probably be recreated;"
"19","22016","2016","Jan-Henrik Haunert, Wouter Meulemans","Partitioning Polygons via Graph Augmentation","F","FO","CG","0","NA","1","0","1","FO: insufficient information to recreate the input data; no pre-processing needed"
"20","32016","2016","Carson J. Q. Farmer, Carsten Keßler","Hierarchical Prism Trees for Scalable Time Geographic Analysis","F","CG","MK","2","2","2","0","2","MK: Everything inlcuded in one Jupyther Notebook, well done. Bu I could not find a description for the computational environment. CG: that's true. Computational environment set to 0"
"21","42016","2016","Emre Eftelioglu, Yan Li, Xun Tang, Shashi Shekhar, James M. Kang, Christopher Farah","Mining Network Hotspots with Holes: A Summary of Results","F","MK","BH","1","0","1","0","1","BH: didn't find any mention of the computer used; links to open data repositories given; methods described in formulas; figures as graphs and with discussion
MK: Agreed. Description of the input data is rather bad though, but it should be possible with lots of effort to replicate the data.
DN: ""For both of the case studies, we matched activities to edges as counts."" > this is a clear preprocessing step for me, given the actual method; the ""Post-processing of the Output"" falls under""results""; preprocessing step is merging of the datasets, matching the incidents to the road network - not properly described with ""activities were matched and their counts on edges were aggregated"";"
"22","52016","2016","KwangSoo Yang","Distance-Constrained k Spatial Sub-Networks: A Summary of Results","F","BH","DN","0","0","1","1","1","DN: case study shows computational costs can be reduced > there must be an implementation; data ""from OpenStreetMap""; crime data download links still work, but one requires a login; ""For simplicity, we mapped all incidents to the nearest edge;"" is a preprocessing step, which is not enough documentation IMO;

BH: agree to your evaluation; preprocessing not described at all

DN: preprocessing step is merging of the datasets, matching the incidents to the road network - not properly described with ""nearest edge"";"
"23","62016","2016","Dipto Sarkar, Renee Sieber, Raja Sengupta","GIScience Considerations in Spatial Social Networks","T",NA,NA,NA,NA,NA,NA,NA,NA
"24","72016","2016","Takeshi Shirabe","On Distortion of Raster-Based Least-Cost Corridors","F","DN","CG","0","0","1","0","1","""For numerical experiments, the algorithm reviewed in the previous section was implemented in Java adapting Dijkstra’s shortest path algorithm""; ""As for elongation, numerical experiments found some interesting pattern ..."" > DN: I don't find any mention of code or data; I see the creation of the cost surface as preprocessing, which is not even documented IMO;"
"25","82016","2016","Joseph V. Tuccillo, Barbara P. Buttenfield","Model-Based Clustering of Social Vulnerability to Urban Extreme Heat Events","F","FO","MK","1","1","1","0","1","MK: I couldn't find a link to the input data. So I gave 1 for input: FO: agree, changed my score from 2 to 1"
"26","92016","2016","Jiaoli Chen, Shih-Lung Shaw","Representing the Spatial Extent of Places Based on Flickr Photos with a Representativeness-Weighted Kernel Density Estimation","F","CG","BH","1","1","1","0","1","Flickr data - they described which Flickr data their downloaded; what I do not know is whether the Flickr database remains stable over years or pictures get deleted by users -I doubt that it is possible to download the exact same dataset a couple of years later"
"27","102016","2016","Tuhin Paul, Kevin Stanley, Nathaniel Osgood, Scott Bell, Nazeem Muhajarine","Scaling Behavior of Human Mobility Distributions","F","MK","BH","0","1","1","1","1","Data sources are referenced, but I have the impression that not all GPS data collections are openly accessible. Preprocessing steps listed in the text - reproducibility possible with effort.
MK: Agreed"
"28","112016","2016","Ashwin Shashidharan, Derek B. van Berkel, Ranga Raju Vatsavai, Ross K. Meentemeyer","pFUTURES: A Parallel Framework for Cellular Automaton Based Urban Growth Models","F","BH","FO","0","0","1","1","1","BH: I rechecked the preprocessing aspects of the paper: they are part of the workflow and include data partitioning among 'workers'. However, for the experiments it is not described how this is acutally done. could be 0 as well."
"29","122016","2016","Qinghan Liang, Silvia Nittel, Torsten Hahmann","From Data Streams to Fields: Extending Stream Data Models with Field Data Types","T",NA,NA,NA,NA,NA,NA,NA,NA
"30","132016","2016","Joshua A. Lewis, Max J. Egenhofer","Point Partitions: A Qualitative Representation for Region-Based Spatial Scenes in R2","T",NA,NA,NA,NA,NA,NA,NA,NA
"31","142016","2016","Xiaoxiao Liu, Stefania Bertazzon","Fine Scale Spatio-Temporal Modelling of Urban Air Pollution","F","DN","MK","0","1","1","0","1","AEMERA data services seem offline: airdata.aemera.org
Data acquisition, model selection, and other details are published elsewhere [24]"", but ref 24 does not help me finding the data, but has model description
MK: I find it difficult to give 0 for results, which actually means that the paper has no results and does not make any sense at all. And I think there is a description of the results. > DN's assessment adjusted to 1."
"32","152016","2016","Matt Duckham, Marc van Kreveld, Ross Purves, Bettina Speckmann, Yaguang Tao, Kevin Verbeek et al.","Modeling Checkpoint-Based Movement with the Earth Mover’s Distance","F","FO","CG","2","1","1","0","1","FO: input data is not available anymore, but was at the time of the publication; since this is four years ago, I would still give it a ""2"""
"33","162016","2016","Benjamin Adams, Mark Gahegan","Exploratory Chronotopic Data Analysis","F","CG","DN","1","1","1","0","1","Input data: ""we used the August 8, 2015 dump of the English Wikipedia, which consists of 7,131,349 articles of which 4,659,056 are actual article pages"". CG: I've  assigned a level of 2 acording to https://en.wikipedia.org/wiki/Wikipedia:Database_download DN: I don't see any chance to access a dump from 2015 easily, could possibly recreate the 2015 data dump with scripting or re-run workflow with current data dump;

""We leveraged existing open source tools to accomplish this task, but due to the large size of the data, custom analytic scripts were developed to explore the results.""; mention HPC cluster with 3000 cores;"
"34","172016","2016","Christopher Allen, Thomas Hervey, Sara Lafia, Daniel W. Phillips, Behzad Vahedi, Werner Kuhn","Exploring the Notion of Spatial Lenses","F","MK","FO","1","1","1","0","1","FO: this is a difficult case, because it has 5 case studies, each of which goes farther in trying to assure reproducibility than most other papers, with URLs to various data sources, and also links to tools being used; however, when applying the rule to assign the lowest score, the paper only gets a ""1"" 
MK: I would give a 1 for the preprocessing described in 3.1 and 3.2
 FO: agree, changed my score from 0 to 1"
"35","182016","2016","Krzysztof Janowicz, Yingjie Hu, Grant McKenzie, Song Gao, Blake Regalia, Gengchen Mai et al.","Moon Landing or Safari? A Study of Systematic Errors and Their Causes in Geographic Linked Data","F","FO","CG","1","0","1","0","1","FO: much of the analysis is based on single, exemplary queries that are given; however, the underlying data set is not available, as is the procedure to produce the initial map that guides the remainder of the analysis"
"36","192016","2016","Arthur van Goethem, Marc van Kreveld, Bettina Speckmann","Circles in the Water: Towards Island Group Labeling","F","DN","MK","0","NA","1","0","1","""We use digitized island groups from several atlases together with their respective labels.""
""To ensure we obtained realistic solutions we computed label positions having the same height as the original manual label."" > so there is code, even more for the Comparison, but not mentioned.
MK: Section 2 (particularly 2.1) sounds like preprocessing, since they speak about reducing the complexity..."
"37","202016","2016","Benjamin Niedermann, Martin Nöllenburg","An Algorithmic Framework for Labeling Road Maps","F","FO","DN","2","1","1","1","2","""As proof of concept we implemented the core of the framework only taking the most important cartographic criteria into account.""

https://i11www.iti.kit.edu/roadlabeling/berlin/compare.html does not work anymore because of JavaScript problem; no license, personal website"
"38","212016","2016","Peter Kiefer, Ioannis Giannopoulos, Andrew Duchowski, Martin Raubal","Measuring Cognitive Load for Map Tasks Through Pupil Diameter","F","CG","FO","1","1","1","1","1",NA
"39","12014","2014","Thomas C. van Dijk, Arthur van Goethem, Jan-Henrik Haunert, Wouter Meulemans, Bettina Speckmann","Map Schematization with Circular Arcs","F","MK","CG","0","NA","1","0","1",NA
"40","22014","2014","Kevin Buchin, Arthur van Goethem, Michael Hoffmann, Marc van Kreveld, Bettina Speckmann","Travel-Time Maps: Linear Cartograms with Fixed Vertex Locations","F","DN","MK","0","NA","1","0","1","""we tested our heuristics on three scenarios based on real-life data [..] create 50 random scenarios of each type""; examples are still online at https://www.win.tue.nl/~agoethem/linear_cartograms/#animated but animations don't work (need Flash player); direct links to the movies work: http://www.win.tue.nl/~agoethem/linear_cartograms/movies/wiggly1.flv; there is data, and it is used for the plots, but not mentioned at all, also not how the maps are created;"
"41","32014","2014","Sara Irina Fabrikant, Sara Maggi, Daniel R. Montello","3D Network Spatialization: Does It Add Depth to 2D Representations of Semantic Proximity?","F","DN","FO","1","1","1","1","1","DN: controlled human-subject experiments using 3D displays; the comp env is very generous, considering they only mention one software version; limitations as to personal data for results not clear (could be completely anonymised!)

FO: not sure why NA in analysis, the ANOVA and so forth are regular analysis for me;, also, enough information is given to recreate a similar data set - if this is a 0, then all user studies are either 0 or 2, but never 1; pre-processing is in ""set-up and materials"" paragraphs;

DN: good points > adjusted the assessment"
"42","42014","2014","Paul Holloway, Jennifer A. Miller","Uncertainty Analysis of Step-Selection Functions: The Effect of Model Parameters on Inferences about the Relationship between Animal Movement and the Environment","F","FO","CG","2","1","1","0","1","CG: Handle to input data provided (ref 25) but link is broken! I did not get access to ref 26 either . Refs in table: 27 is a presentation in pdf, 28 link is broken, 29 link works and it seems data can be downloaded but registration is required. It would have scored quite high but I cannot access most of the data.  I do not how to treat this case FO: I vote for 2, because the links are there and we can assume that they worked in 2014; not sure why you gave 0 for analysis, because it uses more or less standard libaries and methods, all of which it mentions, thus it should be possible with quite some effort to replicate the analysis. CG (in response): I do not know why I scored 0 in analysis. My fault!
DN: Following 152016 decision, input data get's a 2 for historic availability, but we cannot tell if the URL ever existed, see https://web.archive.org/web/*/https://hdl.handle.net/10255/move.269"
"43","52014","2014","Kris Hatch, Suzana Dragićević, Jozo Dujmović","Logic Scoring of Preference and Spatial Multicriteria Evaluation for Urban Residential Land Use Analysis","F","CG","MK","0","1","1","0","1","CG: data & software -> 1st par section 3.1CG: I d"
"44","62014","2014","François Bavaud","Spatial Weights: Constructing Weight-Compatible Exchange Matrices from Proximity Matrices","F","DN","FO","0","0","1","0","1","MK: I can't evaluate this paper properly. Good luck.

DN: largely a math paper, but Figures definetely rely on data and include statistical measures; I suggest 00101; FO: 00101"
"45","72014","2014","Guillaume Guex","Spatial Graphs Cost and Efficiency: Exploring Edges Competition by MCMC","F","FO","DN","1","1","1","0","1","DN: data is randomly drawn, so I suppose reader could recreate a random one, too; algorithms are just formulas + references; city data from R package, but lacks version andcode; FO: more straightforward paper for reproducibility evaluation; agree with your judgments"
"46","82014","2014","Sophia Karagiorgou, Dieter Pfoser, Dimitrios Skoutas","Geosemantic Network-of-Interest Construction Social Media Data","F","DN","CG","1","1","1","0","1","DN: geocoded Tweets > cannot be republished, I guess, also using OSM data > could recreate a similar enough dataset; algorithm in pseudo-code and text;"
"47","92014","2014","Ahmed Loai Ali, Falko Schmid","Data Quality Assurance for Volunteered Geographic Information","F","FO","MK","1","1","1","0","1","FO: gives at least exact day of OSM download, but still too much relevant information is missing"
"48","102014","2014","Mark Gahegan, Benjamin Adams","Re-Envisioning Data Description Using Peirce’ Pragmatics","T","CG","MK",NA,NA,NA,NA,NA,"CG: link to first data set (footnote) is broken. Links to second dataset is given as an ""id"" in dataone (instead of full doi/url). Rather theoretical paper (describing a model of geographic data semantics and pragmatics), even though a Bayesian experiment is described but as a ""thought experiment""
MK: I think this paper is a conceptual paper. They take the two datasets to evaluate them. It is a meta-analysis which is a bit similar to ours. So I don't think this paper relevant for our analysis.
DN: changed to conceptual paper, ratings were CG:xNA101 and MK:NANANANANA"
"49","112014","2014","Gilberto Camara, Max J. Egenhofer, Karine Ferreira, Pedro Andrade, Gilberto Queiroz, Alber Sanchez et al.","Fields as a Generic Data Type for Big Spatial Data","F","MK","DN","1","1","1","0","1","evaluation of a software with MODIS data; unclear which SciDB version was used, hardware is mentioned;"
"50","122014","2014","Werner Kuhn, Tomi Kauppinen, Krzysztof Janowicz","Linked Data - A Paradigm Shift for Geographic Information Science","T",NA,NA,NA,NA,NA,NA,NA,NA
"51","132014","2014","Gaurav Sinha, David Mark, Dave Kolas, Dalia Varanka, Boleslo E. Romero, Chen-Chieh Feng et al.","An Ontology Design Pattern for Surface Water Features","T",NA,NA,NA,NA,NA,NA,NA,"MK: I dont think this is a relevant paper. It is about the development of an ontology which is rather conceptual. They could have implemented it as mentioned in 4.2 but this was not part of the paper. 

DN: Good! Marked as conceptual."
"52","142014","2014","Johannes Scholz, Stefan Schabus","An Indoor Navigation Ontology for Production Assets in a Production Environment","F","MK","CG","0","NA","0","0","1","CG: As regard the ontology model, the paper can be labelled as conceptual, but it also includes an application prototype and routing alg. in indoor spaces. No pre-processing at all"
"53","152014","2014","Ioannis Giannopoulos, Peter Kiefer, Martin Raubal, Kai-Florian Richter, Tyler Thrash","Wayfinding Decision Situations: A Conceptual Model and Evaluation","F","DN","FO","1","1","1","0","1","DN: human-experiment data collected in outdoor wayfinding study; the ""data post processing"" is preprocessing before the analysis; extraction of measures by human raters is method/processing; used a 3D model in GIS (mention ArcGIS version, but for Web Experiment only ""using JavaScript""), but don't mention the data source; the 1 in data is generous IMO; vcustom genetic algorithm described as text; statistical results and model parameters are provided;"
"54","162014","2014","William Mackaness, Phil Bartie, Candela Sanchez-Rodilla Espeso","Understanding Information Requirements in “Text Only” Pedestrian Wayfinding Systems","F","DN","MK","1","NA","1","0","1","human subject experiments at street level > impossible to recreate?!; rather loose description of data sources, ""We built a citiy model [...] a variety of open source data, data scraped from [...]""; Ordnance Survey MasterMap;

DN: They could have published the finished city model, their app, and CSV files with instructions; AFAICS the full questionnair is not described;

MK: Regarding data, I would give it a 1 due to the description provided in 4.1, the figures, and table 4. 
Preprocessing: I coudnt find information about that. I can only assume that there must be some preprocessing somewhere.
Regarding the method: Yes, it would be a lot of effort and the quest is missing but from the results you could infer the questions a bit which could be sufficient

DN: fair points, and for consistency with others (like the previous paper) I think a 1 is better for a well-described human subject study; re. the reconstructions of the survey: then if a survey is made, there will never be a 0 - fine by me."
"55","172014","2014","Ludovic Moncla, Mauro Gaio, Sébastien Mustière","Automatic Itinerary Reconstruction from Texts","F","FO","MK","1","1","1","0","2","FO: working link to working demonstration providedy, for this I gave a 2 on results (you can experiment and see what the outcomes are, however there is no proper way to check what happens behind the screens, beyond the description in the paper)
MK: Regarding results: I would give it only a 1, since for assigning 2, it needs to be scripted, doesn't it?"
"56","182014","2014","Jing Wang, Stephan Winter, Daniel Langerenken, Haifeng Zhao","Integrating Sensing and Routing for Indoor Evacuation","F","CG","DN","0","NA","1","0","1","YAMAMOTO (C#) software is mentioned (http://www.informatik.uni-bremen.de/~tlaue/publications/YamamotoSimRobot-ISAmI-2010.pdf - but nothing cited!) and a system framework is described, including an app screenshot, but no version is given and the graphs and building models are not published; DN: there is simulation, but no discernable data preprocessing;"
"57","192014","2014","Dev Oliver, Shashi Shekhar, Xun Zhou, Emre Eftelioglu, Michael R. Evans, Qiaodi Zhuang et al.","Significant Route Discovery: A Summary of Results","F","MK","FO","2","0","1","0","1","FO: all input data set have links to the providing organization (but not the data sets themselves) but because all come from ""reputable"" open sources, I am inclined to give a 2
MK: 
Data: Yes, but I wouldn't know which data since there different years provided
Prepr.: I am not sure if there is any preprocessing since the algorithm runs on the network as it is or what exactly would you consider as being preproc.?
Comp. Env.: Here we might have a conflict with the paper in line 55 where the the hardware was also described but no software version were given. There, we gave it a 0."
"58","202014","2014","A. K. M. Mustafizur Rahman Khan, Tanzima Hashem, Egemen Tanin, Lars Kulik","Location Oblivious Privacy Protection for Group Nearest Neighbor Queries","F","DN","CG","2","NA","1","0","1","CG: Again, link to data is broken.In this case, however, I would kept the score to 0 as the link to data provided in the paper is invalid. The link did not work at that time either

DN: new algorithm for GNN detection, safer and faster, including data exchange protocols, both defined with formulas/pseudocode; experimental setup, authors report on synthetic and real data; normalisation of data space could be preprocessing; data URL is broken because of LaTeX code, http://www.cs.utah.edu/~lifeifei/SpatialDataset.htm works (including a web archive snapshot: https://web.archive.org/web/20200527003830/http://www.cs.utah.edu/~lifeifei/SpatialDataset.htm !), but not license information, and all original data source links broken; BUT synthetic data is not provided; hardware is documented, but nothing on code; plenty of result plots and statistics;"
"59","212014","2014","Frank Kammer, Maarten Löffler, Paul Mutser, Frank Staals","Practical Approaches to Partially Guarding a Polyhedral Terrain","F","DN","FO","1","NA","1","0","1","DN: new algorithm for placing points with viewsheds on a polyhedral terrain (DEM); experimentally validate their main observations/practical greedy algorithms/lower bound of complexity; algorithms as pseudo-code in text; implemented approaches; precomputing is part of one workflow (not preprocessing in our categories); mention data source but not precise locations (only names); coarse and fine variants of data is preprocessing;"
"60","222014","2014","Joshua A. Lewis, Max J. Egenhofer","Oriented Regions for Linearly Conceptualized Features","T",NA,NA,NA,NA,NA,NA,NA,NA
"61","232014","2014","Eliseo Clementini, Anthony G. Cohn","RCC*-9 and CBM*","T",NA,NA,NA,NA,NA,NA,NA,NA
"62","12012","2012","Amin Abdalla, Andrew U. Frank","Combining Trip and Task Planning: How to Get from A to Passport","T",NA,NA,NA,NA,NA,NA,NA,NA
"63","22012","2012","Chris Anderson-Tarver, Mike Gleason, Barbara Buttenfield, Larry Stanislawski","Automated Centerline Delineation to Enrich the National Hydrography Dataset","F","FO","DN","2","1","1","1","1","DN: paper presents revised algorithm for national dataset (should be openly available) and show results for six study areas, showing perfomance; direct data URL is redirected, but NHD (and validation dataset NHDPlus MR) can still be found and searching for the ""Subbasin ID"" also yields useful results (https://www.sciencebase.gov/catalog/item/5a58a428e4b00b291cd684c2) (even if not from 2012); USGS should be almost permanent, but policies can changes so I stuck to level 2; implementation in Python with ArcPy for ArcGIS 10; provide runtime results and used hardware;

Authors mention preprocessing steps in section 4.1"
"64","32012","2012","Kevin Buchin, Bettina Speckmann, Sander Verdonschot","Evolution Strategies for Optimizing Rectangular Cartograms","F","CG","FO","1","1","1","1","1","CG: regular edge labelings (REL) can be viewed as prepocessing. On page 34, it's said ""To create a cartogram from an REL we follow the iterative linear programming method"". So, cartogram creation can be the analysis part. Data: some links are broken. Sw libraries/OS mentioned. FO: I gave data a 2, because they provide links to the portals with good descriptions what they used; it is not a full 2 according to our criteria, but they did it much better than many 1 scores, so I think that it should be 'rewarded'; DN: general guidelines is to award the lower (see PeerJ paper)"
"65","42012","2012","Maike Buchin, Somayeh Dodge, Bettina Speckmann","Context-Aware Similarity of Trajectories","F","MK","CG","2","1","1","0","1",NA
"66","52012","2012","Yao-Yi Chiang, Craig A. Knoblock","Generating Named Road Vector Data from Raster Maps","F","BH","MK","1","NA","1","0","1","MK: I think there is no explicit reprocessing going on. Imo everything is part of the algorithm; BH: unless we see the previous algorithmes to extract roads and text as the preprocessing for joining the two as described in this paper; overall a rather generously evaluated paper"
"67","62012","2012","Matthew P. Dube, Max J. Egenhofer","An Ordering of Convex Topological Relations","T",NA,NA,NA,NA,NA,NA,NA,NA
"68","72012","2012","Julien Gaffuri","Toward Web Mapping with Vector Data","F","DN","FO","0","NA","1","0","1","FO: I am tempted to classify this as conceptual paper; the experimental part is really small (just one page) and crucial for the paper's objectives. 

DN: fixing performance issue of vector web maps, framework with specific formats, tiling, spacial index > implemented prototype; the described platform is mostly defined via requirements and references, but no technical details that would help me to reimplement the prototype; http://www.opencarto.goldzoneweb.info/ is offline, but it did exist, see https://web.archive.org/web/20111002213548/http://www.opencarto.goldzoneweb.info/, and the sourceforge code hosting is also offline; I agree this borders on a conceptual paper ""requirements for web mapping w/ vector data"", but there is a prototype; with considerable effort, something close enough could be re-implemented;"
"69","82012","2012","Carsten Keßler, Krzysztof Janowicz, Tomi Kauppinen","spatial@linkedscience – Exploring the Research Field of GIScience with Linked Data","F","FO","CG","2","1","1","1","2","CG: Web site http://spatial.linkedscience.org/ is no longer available FO: the problem here is that from their description, lots of analysis etc. was available on that website, but we can't check now; I am inclined to give them the benefit of the doubt and give them scores of 2, but I realize that I am too biased b/c of Carsten; needs group discussion"
"70","92012","2012","Nicolas Maisonneuve, Bastien Chopard","Crowdsourcing Satellite Imagery Analysis: Study of Parallel and Iterative Models","F","CG","MK","0","0","1","0","1","CG: No acces to data generated by participants. Preprocesssing is done by participants through Amazon Mechanical Turk.
MK: I couldn't find info on preprocessing"
"71","102012","2012","Pradeep Mohan, Xun Zhou, Shashi Shekhar","Quantifying Resolution Sensitivity of Spatial Autocorrelation: A Resolution Correlogram Approach","F","MK","BH","0","1","1","1","1","MK: Enough info on comp. env. for a 1? Could not find the referenced data; BH: couldn't find data either, but might be easy for someone working with climate data; preprocessing is the generation of different resolutions of the raster images, no? that is documented; comp. env - couldn't find details on that

DN: RSA algorithm is not part of their work, I agree this is preprocessing"
"72","112012","2012","Silvia Nittel, Christopher Dorr, John C. Whittier","LocalAlert: Simulating Decentralized Ad-Hoc Collaboration in Emergency Situations","F","BH","DN","NA","NA","2","1","1","DN: present open source agent simulation framework; text describes model ""space"" and abilities/behaviours of agents, and the different tested strategies; examples for available framework parameters are given; implementation based on NetLogo (version not mentioned), code is still archived at https://code.google.com/archive/p/gaem/source/default/source; sadly no README, a NetLogo user could possibly run this; the frame.nlogo seems to configure ""experiments"" that could match the evaluation variants described in the paper; output data not ""saved"" but potentially recreatable; BH: data = described parameters for agents defined in the simulation?

FO/CG: configuration is part of analysis"
"73","122012","2012","Avinash Rude, Kate Beard","High-Level Event Detection in Spatially Distributed Time Series","F","DN","CG","0","1","1","0","1","CG: barometric data smooth --> preprocessing. Regarding input data, it only mentions the GOMOOS system (pretty much the same as 'available upon request')

DN: approach illustrated with simulated time series data, then with real data of an ocean observing system, compared agains NCDC reported events; no information about how simlated data was generated, also not available, just a Figure with the plotted data; GoMOOS data not sufficiently described (time yes, but not which buoys, though with some digging one might infer them from the maps...); data smoothing with low-pass filter is preprocessing; NCDC storm database still available (under different URL), so a partial ""1"" for data; results are shown with plots/maps;"
"74","132012","2012","Thiago Luís Lopes Siqueira, Cristina Dutra de Aguiar Ciferri, Valéria Cesário Times, Ricardo Rodrigues Ciferri","Towards Vague Geographic Data Warehouses","F","MK","FO","0","NA","2","0","2","FO: Difficult case; I gave the scores of 2 because of the link, and the 0 because I could not find any information on the input data nor how it was preprocessed (if at all); they give us reproducible details on a case study DB without the actual data... 
MK: Not sure if there is any preprocessing going on. I couldn't find information on comp. env."
"75","142012","2012","Guibo Sun, Hui Lin, Rongrong Li","Measuring the Influence of Built Environment on Walking Behavior: An Accessibility Approach","F","FO","MK","1","1","1","0","1","FO: I was tempted for 0 for data, because I could not find any information on the DEM; however, a DEM for that area is certainly easily available, so I guess a 1 is okay
MK: I couldn't find information on comp. env."
"76","152012","2012","Guillaume Touya","Social Welfare to Assess the Global Legibility of a Generalized Map","F","CG","BH","0","NA","1","0","1",NA
"77","162012","2012","Jan Oliver Wallgrün, Jinlong Yang, Alexander Klippel, Frank Dylla","Investigations into the Cognitive Conceptualization and Similarity Assessment of Spatial Scenes","F","MK","DN","1","NA","1","1","1","DN: three human experiments; icon sets could be provided, especially the ones after manual selection; describe hardware and software (CatScan, with paper ref) in text;

MK: I coud not find info on comp. env."
"78","172012","2012","Lisa A. Walton, Michael Worboys","A Qualitative Bigraph Model for Indoor Space","T",NA,NA,NA,NA,NA,NA,NA,NA
"79","182012","2012","Toyohide Watanabe, Kosuke Yamamoto","Dynamic Refuse Collection Strategy Based on Adjacency Relationship between Euler Cycles","F","BH","FO","2","NA","1","0","1","FO: pdf has three blank pages where the simulation would be; can't assess it; BH: I have no issues with the document; link to data could be restored; comp. env. not specified SOLVED"
"80","192012","2012","Ting Wei, Scott Bell","Impact of Indoor Location Information Reliability on Users’ Trust of an Indoor Positioning System","F","DN","MK","1","NA","1","0","1","DN: human subject study; SaskEPS software; created data should be shared;"
"81","202012","2012","Nancy Wiegand","Ontology for the Engineering of Geospatial Systems","F","FO","BH","1","NA","1","0","1","BH: they say that they used Twinkle - is that sufficient as description of the comp. eng?  http://semanticweb.org/ontologies/2010/3/9/Ontology1270863566125.owl   FO:Agree"
"82","212012","2012","Nancy Wiegand","Preserving Detail in a Combined Land Use Ontology","F","CG","DN","1","1","1","0","0","DN: ""custom Java code"" already mentioned in the abstract :-); ""established once then myriad uses""; indented bullet lists in Word as database, manual work; https://ontohub.org/socop/WisLandUseCodes///symbols?kind=Class; CG: I see prepocessing as the manual process of creating the ontology"
"83","222012","2012","Michael Worboys","The Maptree: A Fine-Grained Formal Representation of Space","T",NA,NA,NA,NA,NA,NA,NA,NA
"84","232012","2012","Hui Yang, Gefei Feng","Automatic Creation of Crosswalk for Geospatial Metadata Standard Interoperability","F","MK","FO","1","0","1","0","1","MK: I am fine with the results. Not sure if preprocessing is happening"
"85","242012","2012","KwangSoo Yang, Venkata M. V. Gunturi, Shashi Shekhar","A Dartboard Network Cut Based Approach to Evacuation Route Planning: A Summary of Results","F","BH","CG","2","NA","1","1","1","CG: link to data is broken; however, US Census/Tiger is a well-respected source, so it is essy to get the input data; BH: data are available, but have been updated in the meantime - but that is ok, I suppose"
"86","252012","2012","Eman M. G. Younis, Christopher B. Jones, Vlad Tanasescu, Alia I. Abdelmoty","Hybrid Geo-spatial Query Methods on the Semantic Web with a Spatially-Enhanced Index of DBpedia","F","DN","BH","1","NA","1","0","1","DN: ""filtered manually"", instructions are detailed, could potentially, with a lot of effort, recreate dataset somehow close to the original _for today_; Ordenance Survey and DBpedia still exist..."
"87","262012","2012","Yihong Yuan, Martin Raubal","Extracting Dynamic Urban Mobility Patterns from Mobile Phone Data","F","FO","DN","0","1","1","0","1","DN: they could have provided the voronoi poloygons with aggregated data; all processing is ""documented as text"" in section 3.2.1;

FO: the steps described in 3.2 could be considered steps of the main method

The authors distinguish between 3.2.1 and 3.2.2 (main method), so they also see the Voronoi polygon creation as preprocessing."
