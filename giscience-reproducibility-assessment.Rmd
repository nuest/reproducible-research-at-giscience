---
title: 'Reproducibility assessment data analysis for "Reproducible research and GIScience: an evaluation using GIScience conference papers"'
author: "Daniel Nüst, Carlos Granell"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    df_print: paged
    toc: yes
urlcolor: blue
---

<style type="text/css">
/* https://gist.github.com/Pakillo/8b46a48ea806572566d9 and
   https://stackoverflow.com/questions/36845178/width-of-r-code-chunk-output-in-rmarkdown-files-knitr-ed-to-html#36846864 */
/*body, td {
   font-size: 14px;
}
code.r{
  font-size: 12px;
}*/
pre {
  font-size: 12px
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
</style>

This document visualises the expert assessment for accepted full papers at the [GIScience conference series](https://www.giscience.org/) for the following conferences and proceedings.

- 2018: Tenth International Conference on Geographic Information Science, Melbourne, Australia
  
  _Proceedings 10th International Conference on Geographic Information Science (GIScience 2018). 2018. In Winter, S., Griffin, A., Sester, M. (Eds.), LIPICS Vol. 114. ISBN 978-3-95977-083-5. http://www.dagstuhl.de/dagpub/978-3-95977-083-5 _

- 2016: Ninth International Conference on Geographic Information Science, Sep 27, 2016 - Sep 30, 2016, 	Montreal, Canada
  
  _Geographic Information Science. 2016. In J. A. Miller, D. O’Sullivan, & N. Wiegand (Eds.), Lecture Notes in Computer Science. Springer International Publishing. https://doi.org/10.1007/978-3-319-45738-3 _

- 2014: Eighth International Conference on Geographic Information Science, Sep 24, 2014 - Sep 26, 2014, 	Vienna, Austria
  > Geographic Information Science. 2014. In M. Duckham, E. Pebesma, K. Stewart, & A. U. Frank (Eds.), Lecture Notes in Computer Science. Springer International Publishing. https://doi.org/10.1007/978-3-319-11593-1

- 2012: Seventh International Conference on Geographic Information Science, Sep 18, 2012 - Sep 21, 2012, Columbus, Ohio, USA
  > Geographic Information Science. 2012. In N. Xiao, M.-P. Kwan, M. F. Goodchild, & S. Shekhar (Eds.), Lecture Notes in Computer Science. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-33024-7

The analysis is based on the assessment first published in _"Reproducible research and GIScience: an evaluation using AGILE conference papers"_ ([https://doi.org/10.7717/peerj.5072](https://doi.org/10.7717/peerj.5072)), see [https://github.com/nuest/reproducible-research-and-giscience](https://github.com/nuest/reproducible-research-and-giscience).

## Reproduce paper

To create the assessment result data and figures based on this document you can run the following commands in a new R session after completing the prerequisites with the original paper corpus data.
If you have problems rendering the document you can execute each chunk independently in [RStudio](https://rstudio.com/products/rstudio/).

```{r render_with_rmarkdown, eval=FALSE}
require("knitr")
require("rmarkdown")
rmarkdown::render("giscience-reproducibility-assessment.Rmd")
```

## Software dependencies and code

This document does not install the required R packages by default.
You can run the script `install.R` to install all required dependencies on a new R installation, or use `install.packages(..)` to install missing R packages.
_This is not required if you use the Docker container provided by the authors._

```{r install_r, eval=FALSE}
source("install.R")
```

The plots and tables of survey data and evaluation use the packages [`ggplot2`](http://ggplot2.tidyverse.org/), [`knitr::kable()`](https://yihui.name/knitr/), [`huxtable`](https://hughjonesd.github.io/huxtable/), and [`kableExtra`](https://cran.r-project.org/package=kableExtra).
Required libraries and runtime environment description are as follows.

```{r load_libraries, echo=TRUE, message=FALSE}
library("tidyverse")
library("readr")
library("ggplot2")
library("reshape2")
library("ggthemes")
library("grid")
library("gridBase")
library("gridExtra")
library("kableExtra")
library("huxtable")
library("here")
library("googlesheets4")
library("patchwork")
```

## Load data

```{r evaldata_file}
assessment_file <- here::here("results/paper_assessment.csv")
codebook_file <- here::here("results/codebook.csv")
```

The data is loaded from a collaborative spreadsheet using the `googlesheets4` package.
After a year is completed by all assessors, a [named version] of the spreadsheet is created.
Then the data file `r assessment_file` is updated from the online spreadsheet and committed to the git history.
Afterwards the individual assessments are manually merged in the online spreadsheet and the data file is updated and committed once more.

```{r googlesheets_auth, echo=FALSE, eval=FALSE}
# run once
googlesheets4::sheets_auth(use_oob = TRUE)
```

```{r evaldata_download, echo=FALSE, eval=FALSE}
assessment_sheet <- googlesheets4::read_sheet(
  ss = "https://docs.google.com/spreadsheets/d/1Df0zX5yqDuDSCzHHVaucNtThseHL5L32U2sWTPhyl0I/edit#gid=0",
  sheet = "assessment",
  # fix type for downloading data: turn all data into character strings; type set later in load
  col_types = "c",
  range = googlesheets4::cell_rows(1:88) # 2018, 2016, 2014, 2012
)

write.csv(assessment_sheet, file = assessment_file)
```

The following plots are based on the data file `r assessment_file`, the result from the manual reproducibility assessment.
The file `r codebook_file` contains a codebook with names, labels, and descriptions for the variables in the data file as documentation of the dataset outside of this computational notebook.

```{r load_evaldata}
category_levels <- c("0", "1", "2", "3")
paper_evaluation <- readr::read_csv(assessment_file, 
    col_types = readr::cols(
      `conceptual paper` = readr::col_logical(),
      `computational environment` = readr::col_factor(levels = category_levels),
      `input data` = readr::col_factor(levels = category_levels),
      `method/analysis/processing` = readr::col_factor(levels = category_levels),
      preprocessing = readr::col_factor(levels = category_levels),
      results = readr::col_factor(levels = category_levels)
      ),
    na = "NA")

paper_evaluation_wo_conceptual <- filter(paper_evaluation, `conceptual paper` == FALSE)

categoryColumns <- c("input data", 
                     "preprocessing",
                     "method/analysis/processing",
                     "computational environment",
                     "results")
```

```{r corpus_table}
options(knitr.kable.NA = '-')
knitr::kable(paper_evaluation %>% 
               dplyr::select(-matches("X1|reviewer|conceptual|authors")),
            format = "html",
            booktabs = TRUE,
            caption = paste0("Reproducibility levels for paper corpus; ",
                             "'-' is category not available")) %>%
  kableExtra::kable_styling("striped", full_width = FALSE)
```

## Table: Statistics of reproducibility levels per criterion for non-conceptual papers

```{r summary_evaldata}
evaldata_numeric <- paper_evaluation_wo_conceptual %>%
  dplyr::filter(`conceptual paper` == FALSE) %>%
  # must convert factors to numbers to calculate the mean and median
  dplyr::mutate_if(is.factor, dplyr::funs(as.integer(as.character(.))))

# https://stackoverflow.com/questions/32011873/force-summary-to-report-the-number-of-nas-even-if-none
summaryna <- function (v) {
  if(!any(is.na(v))){
    res <- c(summary(v),"NA's"=0)
  } else{
    res <- summary(v)
  }
  return(res)
} 

# apply summary independently to format as table
summaries <- sapply(evaldata_numeric[,categoryColumns], summaryna)
exclude_values_summary <- c("1st Qu.", "3rd Qu.")

kable(subset(summaries, !(rownames(summaries) %in% exclude_values_summary)), 
      digits = 1,
      col.names = c("input data", "preproc.", "method/analysis/proc.",
                    "comp. env.", "results"),
      caption = "Statistics of reproducibility levels per criterion (rounded to one decimal place)") %>%
  kableExtra::kable_styling("striped", full_width = FALSE)
```

The preprocessing has `r sum(!is.na(evaldata_numeric$preprocessing))` values, with `0` and `1` around the "middle" resulting in a fraction as the median.

## Data points for text

```{r criteria_numbers}
data_level_zero <- paper_evaluation_wo_conceptual %>% 
  filter(`input data` == 0) %>% 
  count() %>% .$n

data_level_two <- paper_evaluation_wo_conceptual %>% 
  filter(`input data` == 2) %>% 
  count() %>% .$n

preprocessing_included <- paper_evaluation_wo_conceptual %>% 
  filter(!is.na(preprocessing)) %>% 
  count() %>% .$n

methods_and_results_eq_one <- paper_evaluation_wo_conceptual %>% 
  filter(`method/analysis/processing` == 1 & results == 1) %>% 
  count() %>% .$n
```

`r data_level_zero` papers have level `0` and `r data_level_two` have level `2` in the data criterion.

`r preprocessing_included` papers include some kind of preprocessing.

`r methods_and_results_eq_one` papers have level `1` in both methods and results criterion.

## Figure: Results of reproducibility assessment for non-conceptual papers

### Barplot

```{r fig_assessment_results,fig.width=12}
# match the colours to time series plot below
colours <- RColorBrewer::brewer.pal(length(categoryColumns), "Set1")
level_names <- c("0", "1", "2", "3", NA)
breaks <- seq(from = 0, to = nrow(paper_evaluation_wo_conceptual), by = 10)

criteriaBarplot = function(category, main, colour) {
  cat <- enquo(category)
  ggplot2::ggplot(data = paper_evaluation_wo_conceptual,
                aes(!!cat),
                show.legend = FALSE) +
    ggplot2::geom_bar(fill = colours[colour], color = "black") +
    ggplot2::ggtitle(main) +
    ggplot2::xlab("Level") +
    ggplot2::xlim(level_names) +
    #ggplot2::scale_x_discrete(limits = level_names,
    #                          na.translate = TRUE, na.value = "NA") +
    ggplot2::ylab("") +
    ggplot2::scale_y_continuous(breaks = breaks,
                                limits = range(breaks)) +
    #ggplot2::guides(fill = FALSE) + # remove legend
    theme_tufte(base_size = 12) + theme(axis.ticks.x = element_blank())
}

fig_barplot <- patchwork::wrap_plots(
  ncol = 5,
  criteriaBarplot(`input data`,    main = "Input data",    colour = 1),
  criteriaBarplot(`preprocessing`, main = "Preprocessing", colour = 2),
  criteriaBarplot(`method/analysis/processing`,
                  main = "Methods/Analysis/\nProcessing",  colour = 3),
  criteriaBarplot(`computational environment`,
                  main = "Computational\nEnvironment", colour = 4),
  criteriaBarplot(results,         main = "Results", colour = 5)
)

fig_barplot
```

### [WIP] Alluvial plot

Based on package [`ggalluvial`](https://corybrunson.github.io/ggalluvial/).

```{r fig_alluvial}
papers_wide <- paper_evaluation_wo_conceptual %>%
  mutate_if(is.factor, forcats::fct_explicit_na, na_level = "NA") %>%
  group_by(`input data`,
         preprocessing,
         `method/analysis/processing`,
         `computational environment`,
          results) %>%
  tally() %>%
  mutate(code = paste0(`input data`,
                       preprocessing,
                       `method/analysis/processing`,
                       `computational environment`,
                       results))

library("ggalluvial")
ggplot(data = papers_wide,
       aes(axis1 = `input data`, axis2 = preprocessing,
           axis3 = `method/analysis/processing`,
           axis4 = `computational environment`,
           axis5 = results,
           y = n)
       ) +
  scale_x_discrete(limits = c("Input data", "Preprocessing", "Methods/\nAnalysis/\nProcessing", "Computational\nEnvironment", "Results"), expand = c(.2, .05)) +
  xlab("Category") +
  geom_alluvium(aes(fill = code)) +
  geom_stratum() +
  scale_color_brewer(type = "qual", palette = "Set1") +
  #geom_text(stat = "stratum", aes(label = after_stat(stratum))) +
  theme_tufte()
```


## Table: Mean levels per criterion for non-conceptual papers

```{r summary_evaldata_grouped}
means <- lapply(evaldata_numeric %>%
                      select(categoryColumns),
                    summary) %>%
    lapply(`[[`, "Mean") %>%
    as.data.frame()

kable(means,
      digits = 2,
      col.names = c("input data", "preproc.", "method/analysis/proc.", "comp. env.", "results"),
      caption = "Mean levels per criterion for non-conceptual papers") %>%
  kableExtra::kable_styling("striped", full_width = FALSE)
```

## Table: Mean levels averaged across criteria over time for non-conceptual papers

```{r evaldata_summary_by_year_mean}
means_years <- evaldata_numeric %>%
  filter(`conceptual paper` == FALSE) %>%
  group_by(year) %>%
  summarise(mean = mean(c(`input data`, 
                          preprocessing, 
                          `method/analysis/processing`, 
                          `computational environment`, 
                          `results`),
                        na.rm = TRUE),
            `paper count` = n())

means_years_table <- means_years %>% 
        mutate(mean = round(mean, 2), 
               `paper count` = as.character(`paper count`)) %>%
        mutate(labels = str_c(year, " (n = ", `paper count`, ")")) %>%
        column_to_rownames("labels") %>%
        select(mean) %>%
        t()

kable(means_years_table,
      caption = "Summarised mean values over all criteria over time (non-conceptual papers)") %>%
  kableExtra::kable_styling("striped", full_width = TRUE)
```

## Figure: Mean reproducibility levels per category over time for non-conceptual papers

```{r Fig4,fig.height=4,dpi=300}
evaldata_years <- evaldata_numeric %>%
  filter(`conceptual paper` == FALSE) %>%
  group_by(year) %>%
  summarise(input = mean(`input data`, na.rm = TRUE),
         preprocessing = mean(preprocessing, na.rm = TRUE),
            method = mean(`method/analysis/processing`, na.rm = TRUE),
            environment = mean(`computational environment`, na.rm = TRUE),
            results = mean(results, na.rm = TRUE))
paper_count_years <- evaldata_numeric %>%
  filter(`conceptual paper` == FALSE) %>%
  group_by(year) %>%
  summarise(`paper count` = n())

evaldata_years_long <- melt(evaldata_years, id.vars = c("year"))
fig_mean_over_time <- ggplot(evaldata_years_long, aes(year, value)) +
  geom_bar(aes(fill = variable), position = "dodge", stat = "identity") +
  #geom_errorbar(stat = "summary", fun.data = "mean_sdl", 
  #                fun.args = list(mult = 1),
  #                position =  position_dodge(width = 0.9)) +
  ylab("mean value of criterion level") + 
  scale_x_continuous(breaks = evaldata_years$year,
                     labels = paste0(paper_count_years$year, 
                                     " (n=", 
                                     paper_count_years$`paper count`, 
                                     ")")) +
  scale_fill_brewer(palette = "Set1", name = "Category") +
  theme_tufte(base_size = 18) +
  theme(legend.position = c(0.15,0.75), 
        legend.text = element_text(size = 14)) +
  ylim(0, 3) +
  stat_summary(fun.y = mean, fun.ymin = mean, fun.ymax = mean, shape = "-", size = 2) +
  stat_summary(fun.y = mean, geom = "line", linetype = "dotted", mapping = aes(group = 1))

fig_mean_over_time
```

## Figure: Stacked bars of levels per category over time

TODO

## Colorblindness check

_NOTE:_ The following code chunk is not executed by default and is mainly for evaluation during figure development.

```{r colorblindness}
library("colorblindr")

colorblindr::cvd_grid(fig_mean_over_time)
colorblindr::cvd_grid(fig_barplot)
```


## Colophon

This document is licensed under a [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/).
All contained code is licensed under the [Apache License 2.0](https://choosealicense.com/licenses/apache-2.0/).
This document is versioned in a public [git](https://git-scm.com/) repository, [https://github.com/nuest/reproducible-research-at-giscience](https://github.com/nuest/reproducible-research-at-giscience).

**Runtime environment description:**

```{r session_info, echo=FALSE}
options(width = 100)
devtools::session_info(include_base = TRUE)
```

```{r upload_to_drive, eval=FALSE, include=FALSE}
# upload the HTML file to the Reproducibility Committee shared folder
# upload the HTML file and source code to the Reproducibility Committee shared folder
googledrive::drive_auth(use_oob = TRUE)
googledrive::drive_put("giscience-reproducibility-assessment.html", path = googledrive::as_dribble("https://drive.google.com/drive/folders/17EUtM_zCx1gQMea1MHN_5XSVrssxv9GA"))
googledrive::drive_put("giscience-reproducibility-assessment.Rmd", path = googledrive::as_dribble("https://drive.google.com/drive/folders/17EUtM_zCx1gQMea1MHN_5XSVrssxv9GA"))
```
