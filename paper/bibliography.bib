@article{nust_reproducible_2018,
	title = {Reproducible research and {GIScience}: an evaluation using {AGILE} conference papers},
	volume = {6},
	copyright = {All rights reserved},
	issn = {2167-8359},
	shorttitle = {Reproducible research and {GIScience}},
	doi = {10.7717/peerj.5072},
	language = {en},
	journal = {PeerJ},
	author = {Nüst, Daniel and Granell, Carlos and Hofer, Barbara and Konkol, Markus and Ostermann, Frank O. and Sileryte, Rusne and Cerutti, Valentina},
	month = jul,
	year = {2018},
	pages = {e5072}
}

@article{barba_terminologies_2018,
  title = {Terminologies for {Reproducible} {Research}},
  journal = {arXiv:1802.03311 [cs]},
  url = {https://arxiv.org/abs/1802.03311},
  author = {Barba, Lorena A.},
  month = feb,
  year = {2018},
  note = {arXiv: 1802.03311},
  keywords = {Computer Science - Digital Libraries}
}

@article{brunsdon_quantitative_2016,
  title = {Quantitative methods {I}: {Reproducible} research and quantitative geography},
  volume = {40},
  issn = {0309-1325},
  shorttitle = {Quantitative methods {I}},
  doi = {10.1177/0309132515599625},
  language = {en},
  number = {5},
  journal = {Progress in Human Geography},
  author = {Brunsdon, Chris},
  month = oct,
  year = {2016},
  pages = {687--696}
}

@article{muenchow_reviewing_2019,
  title = {Reviewing qualitative {GIS} research—{Toward} a wider usage of open-source {GIS} and reproducible research practices},
  volume = {13},
  issn = {1749-8198},
  doi = {10.1111/gec3.12441},
  language = {en},
  number = {6},
  journal = {Geography Compass},
  author = {Muenchow, Jannes and Schäfer, Susann and Krüger, Eric},
  year = {2019},
  pages = {e12441}
}

@article{Goodchild1992,
  doi = {10.1080/02693799208901893},
  year = {1992},
  month = jan,
  publisher = {Informa {UK} Limited},
  volume = {6},
  number = {1},
  pages = {31--45},
  author = {Michael F. Goodchild},
  title = {Geographical information science},
  journal = {International journal of geographical information systems}
}

@article{donoho_invitation_2010,
  title = {An invitation to reproducible computational research},
  volume = {11},
  issn = {1465-4644},
  doi = {10.1093/biostatistics/kxq028},
  language = {en},
  number = {3},
  journal = {Biostatistics},
  author = {Donoho, David L.},
  month = jul,
  year = {2010},
  pages = {385--388}
}

@article{markowetz_five_2015,
  title = {Five selfish reasons to work reproducibly},
  volume = {16},
  issn = {1474-760X},
  doi = {10.1186/s13059-015-0850-7},
  abstract = {And so, my fellow scientists: ask not what you can do for reproducibility; ask what reproducibility can do for you! Here, I present five reasons why working reproducibly pays off in the long run and is in the self-interest of every ambitious, career-oriented scientist.},
  journal = {Genome Biology},
  author = {Markowetz, Florian},
  month = dec,
  year = {2015},
  keywords = {Reproducibility, Scientific career},
  pages = {274}
}

@inproceedings{kray_reproducible_2019,
  series = {{LIPIcs}},
  title = {Reproducible {Research} in {Geoinformatics}: {Concepts}, {Challenges} and {Benefits} ({Vision} {Paper})},
  volume = {142},
  isbn = {978-3-95977-115-3},
  shorttitle = {Reproducible {Research} in {Geoinformatics}},
  doi = {10.4230/LIPIcs.COSIT.2019.8},
  booktitle = {{COSIT} 2019},
  publisher = {{Schloss Dagstuhl} {Leibniz-Zentrum für Informatik}},
  author = {Kray, Christian and Pebesma, Edzer and Konkol, Markus and Nüst, Daniel},
  editor = {Timpf, Sabine and Schlieder, Christoph and Kattenbeck, Markus and Ludwig, Bernd and Stewart, Kathleen},
  year = {2019},
  pages = {8:1--8:13}
}

@article{Colavizza2020,
    doi = {10.1371/journal.pone.0230416},
    year = {2020},
    month = apr,
    publisher = {Public Library of Science ({PLoS})},
    volume = {15},
    number = {4},
    pages = {e0230416},
    author = {Giovanni Colavizza and Iain Hrynaszkiewicz and Isla Staden and Kirstie Whitaker and Barbara McGillivray},
    editor = {Jelte M. Wicherts},
    title = {The citation advantage of linking publications to research data},
    journal = {{PLOS} {ONE}}
}

@article{reproducible_agile,
  doi = {10.17605/OSF.IO/PHMCE},
  url = {https://reproducible-agile.github.io/},
  author = {N\"{u}st,  Daniel and Ostermann,  Frank and Sileryte,  Rusne and Hofer,  Barbara and Granell,  Carlos and Teperek,  Marta and Graser,  Anita and Broman,  Karl and Hettne,  Kristina},
  title = {{Reproducible Publications at AGILE Conferences}},
  publisher = {Open Science Framework},
  year = {2019}
}

@article{agile_guidelines,
  doi = {10.17605/OSF.IO/CB7Z8},
  author = {N\"{u}st,  Daniel and Ostermann,  Frank and Sileryte,  Rusne and Hofer,  Barbara and Granell,  Carlos and Teperek,  Marta and Graser,  Anita and Broman,  Karl and Hettne,  Kristina},
  title = {{AGILE Reproducible Paper Guidelines}},
  publisher = {Open Science Framework},
  year = {2019}
}

@article{stodden_empirical_2018,
  title = {An empirical analysis of journal policy effectiveness for computational reproducibility},
  volume = {115},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1708290115},
  language = {en},
  number = {11},
  journal = {Proceedings of the National Academy of Sciences},
  author = {Stodden, Victoria and Seiler, Jennifer and Ma, Zhaokun},
  month = mar,
  year = {2018},
  pmid = {29531050},
  pages = {2584--2589}
}

@article{eglen_codecheck_2019,
  title = {{CODECHECK}: {An} open-science initiative to facilitate sharing of computer programs and results presented in scientific publications},
  issn = {2387-3086},
  shorttitle = {{CODECHECK}},
  doi = {10.7557/5.4910},
  language = {en},
  number = {1},
  journal = {Septentrio Conference Series},
  author = {Eglen, Stephen and Nüst, Daniel},
  month = sep,
  year = {2019}
}

@book{giscienceproceedings2018,
  isbn = {978-3-95977-083-5},
  url = {http://www.dagstuhl.de/dagpub/978-3-95977-083-5},
  year = {2018},
  volume = {114},
  publisher = {{LIPIcs}},
  editor = {S. Winter and A. Griffin and M. Sester},
  title = {Proceedings 10th International Conference on Geographic Information Science (GIScience 2018)}
}

@book{giscienceproceedings2016,
  doi = {10.1007/978-3-319-45738-3},
  year = {2016},
  publisher = {Springer International Publishing},
  editor = {Jennifer A. Miller and David O{\textquotesingle}Sullivan and Nancy Wiegand},
  title = {Geographic Information Science}
}

@book{giscienceproceedings2014,
  doi = {10.1007/978-3-319-11593-1},
  year = {2014},
  publisher = {Springer International Publishing},
  editor = {Matt Duckham and Edzer Pebesma and Kathleen Stewart and Andrew U. Frank},
  title = {Geographic Information Science}
}

@book{giscienceproceedings2012,
  doi = {10.1007/978-3-642-33024-7},
  year = {2012},
  publisher = {Springer Berlin Heidelberg},
  editor = {Ningchuan Xiao and Mei-Po Kwan and Michael F. Goodchild and Shashi Shekhar},
  title = {Geographic Information Science}
}

@book{giscienceproceedings2010,
  doi = {10.1007/978-3-642-15300-6},
  year = {2010},
  publisher = {Springer Berlin Heidelberg},
  editor = {Sara Irina Fabrikant and Tumasch Reichenbacher and Marc van Kreveld and Christoph Schlieder},
  title = {Geographic Information Science}
}

@book{giscienceproceedings2008,
  doi = {10.1007/978-3-540-87473-7},
  year = {2008},
  publisher = {Springer Berlin Heidelberg},
  editor = {Thomas J. Cova and Harvey J. Miller and Kate Beard and Andrew U. Frank and Michael F. Goodchild},
  title = {Geographic Information Science}
}

@book{giscienceproceedings2006,
  doi = {10.1007/11863939},
  year = {2006},
  publisher = {Springer Berlin Heidelberg},
  editor = {Martin Raubal and Harvey J. Miller and Andrew U. Frank and Michael F. Goodchild},
  title = {Geographic Information Science}
}

@book{giscienceproceedings2004,
  doi = {10.1007/b101397},
  year = {2004},
  publisher = {Springer Berlin Heidelberg},
  editor = {Max J. Egenhofer and Christian Freksa and Harvey J. Miller},
  title = {Geographic Information Science}
}

@book{giscienceproceedings2002,
  doi = {10.1007/3-540-45799-2},
  year = {2002},
  publisher = {Springer Berlin Heidelberg},
  editor = {Max J. Egenhofer and David M. Mark},
  title = {Geographic Information Science}
}

@Article{freire_et_al:DR:2016:5817,
  author =	{Juliana Freire and Norbert Fuhr and Andreas Rauber},
  title =	{{Reproducibility of Data-Oriented Experiments in e-Science (Dagstuhl Seminar 16041)}},
  pages =	{108--159},
  journal =	{Dagstuhl Reports},
  ISSN =	{2192-5283},
  year =	{2016},
  volume =	{6},
  number =	{1},
  editor =	{Juliana Freire and Norbert Fuhr and Andreas Rauber},
  publisher =	{Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{http://drops.dagstuhl.de/opus/volltexte/2016/5817},
  URN =		{urn:nbn:de:0030-drops-58174},
  doi =		{10.4230/DagRep.6.1.108},
  annote =	{Keywords: Documentation, Reliability, Repeatibility, Replicability, reproducibility, Software}
}

@software{daniel_nust_2020_4032875,
  author       = {Daniel Nüst and Frank Ostermann and Carlos Granell and Barbara Hofer},
  title        = {{Reproducibility package for "Reproducible Research and GIScience: an evaluation using GIScience conference papers"}},
  month        = sep,
  year         = 2020,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.4032875},
  url          = {https://doi.org/10.5281/zenodo.4032875}
}

@article{konkol_computational_2019,
	title = {Computational reproducibility in geoscientific papers: {Insights} from a series of studies with geoscientists and a reproduction study},
	volume = {33},
	issn = {1365-8816},
	shorttitle = {Computational reproducibility in geoscientific papers},
	url = {https://doi.org/10.1080/13658816.2018.1508687},
	doi = {10.1080/13658816.2018.1508687},
	number = {2},
	urldate = {2020-08-18},
	journal = {International Journal of Geographical Information Science},
	author = {Konkol, Markus and Kray, Christian and Pfeiffer, Max},
	month = feb,
	year = {2019},
	keywords = {computational research, Open reproducible research, spatial statistics},
	pages = {408--429}
}

@incollection{egenhofer_contributions_2016,
	address = {Needham, MA},
	title = {Contributions of {GIScience} over the past twenty years},
	copyright = {Licensed under Creative Commons Attribution 4.0 License},
	url = {http://www.gsdiassociation.org/images/publications/AdvancingGIScience.pdf},
	booktitle = {Advancing {Geographic} {InformationScience}: {The} {Past} and {Next} {Twenty} {Years}},
	publisher = {GSDI Association Press},
	author = {Egenhofer, M. and Clarke, K. and Gao, S. and Quesnot, Teriitutea and Franklin, W. and Yuan, M. and Coleman, David},
	editor = {Onsrud, Harlan and Kuhn, Werner},
	year = {2016}
}

@techreport{kemp2013results,
	title = {Results of a survey to rate {GIScience} publication outlets},
	url = {https://agile-online.org/conference_paper/images/initiatives/results_of_a_survey_to_rate_giscience_publications.pdf},
	institution = {AGILE Initiative - GIScience Publication Rating},
	author = {Kemp, Karen and Kuhn, Werner and Brox, Christoph},
	year = {2013}
}

@inproceedings{kesler_spatiallinkedscience_2012,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{spatial@linkedscience} -- {Exploring} the {Research} {Field} of {GIScience} with {Linked} {Data}},
	isbn = {978-3-642-33024-7},
	doi = {10.1007/978-3-642-33024-7_8},
	abstract = {Metadata for scientific publications contain various explicit and implicit spatio-temporal references. Data on conference locations as well as author and editor affiliations – both changing over time – enable insights into the geographic distribution of scientific fields and particular specializations. At the same time, these byproducts of scientific bibliographies offer a great opportunity to integrate data across different bibliographies to get a more complete picture of a domain. In this paper, we demonstrate how the Linked Data paradigm can assist in enriching and integrating such collections. Starting from the bibliographies of the GIScience, COSIT, ACM GIS, and AGILE conference series, we show how to convert the data to Linked Data and integrate the previously separate datasets. We focus on the spatio-temporal aspects and discuss how they help in matching and disambiguating entities such as authors or universities. We introduce a novel user interface to explore the integrated dataset, demonstrating the potential of Linked Data for innovative applications using spatio-temporal information, and discuss how more complex queries can be addressed. While we focus on bibliographies, the presented work is part of the broader vision of a Linked Science infrastructure for e-Science.},
	language = {en},
	booktitle = {Geographic {Information} {Science}},
	publisher = {Springer},
	author = {Ke{\ss}ler, Carsten and Janowicz, Krzysztof and Kauppinen, Tomi},
	editor = {Xiao, Ningchuan and Kwan, Mei-Po and Goodchild, Michael F. and Shekhar, Shashi},
	year = {2012},
	keywords = {Complex Query, Conference Series, Latent Dirichlet Allocation, Link Data, Resource Description Framework},
	pages = {102--115}
}

@article{archmiller_computational_2020,
	title = {Computational {Reproducibility} in {The} {Wildlife} {Society}'s {Flagship} {Journals}},
	volume = {84},
	copyright = {© 2020 The Authors. The Journal of Wildlife Management published by Wiley Periodicals, Inc. on behalf of The Wildlife Society},
	issn = {1937-2817},
	doi = {10.1002/jwmg.21855},
	abstract = {Scientific progress depends upon the accumulation of empirical knowledge via reproducible methodology. Although reproducibility is a main tenet of the scientific method, recent studies have highlighted widespread failures in adherence to this ideal. The goal of this study was to gauge the level of computational reproducibility, or the ability to obtain the same results using the same data and analytic methods as in the original publication, in the field of wildlife science. We randomly selected 80 papers published in the Journal of Wildlife Management and Wildlife Society Bulletin between 1 June 2016 and 1 June 2018. Of those that were suitable for reproducibility review (n = 74), we attempted to obtain study data from online repositories or directly from authors. Forty-two authors did not respond to our requests, and we were further unable to obtain data from authors of 13 other studies. Of the 19 studies for which we were able to obtain data and complete our analysis, we judged that 13 were mostly or fully reproducible. We conclude that the studies with publicly available data or data shared upon request were largely reproducible, but we remain concerned about the difficulty in obtaining data from recently published papers. We recommend increased data-sharing, data organization and documentation, communication, and training to advance computational reproducibility in the wildlife sciences. © 2020 The Authors. The Journal of Wildlife Management published by Wiley Periodicals, Inc. on behalf of The Wildlife Society.},
	language = {en},
	number = {5},
	urldate = {2020-09-17},
	journal = {The Journal of Wildlife Management},
	author = {Archmiller, Althea A. and Johnson, Andrew D. and Nolan, Jane and Edwards, Margaret and Elliott, Lisa H. and Ferguson, Jake M. and Iannarilli, Fabiola and Vélez, Juliana and Vitense, Kelsey and Johnson, Douglas H. and Fieberg, John},
	year = {2020},
	keywords = {data sharing, meta-analysis, open science, reproducibility, research methods, statistical methods},
	pages = {1012--1017}
}

@article{peng_reproducible_2020,
	title = {Reproducible {Research}: {A} {Retrospective}},
	shorttitle = {Reproducible {Research}},
	url = {http://arxiv.org/abs/2007.12210},
	abstract = {Rapid advances in computing technology over the past few decades have spurred two extraordinary phenomena in science: large-scale and high-throughput data collection coupled with the creation and implementation of complex statistical algorithms for data analysis. Together, these two phenomena have brought about tremendous advances in scientific discovery but have also raised two serious concerns, one relatively new and one quite familiar. The complexity of modern data analyses raises questions about the reproducibility of the analyses, meaning the ability of independent analysts to re-create the results claimed by the original authors using the original data and analysis techniques. While seemingly a straightforward concept, reproducibility of analyses is typically thwarted by the lack of availability of the data and computer code that were used in the analyses. A much more general concern is the replicability of scientific findings, which concerns the frequency with which scientific claims are confirmed by completely independent investigations. While the concepts of reproduciblity and replicability are related, it is worth noting that they are focused on quite different goals and address different aspects of scientific progress. In this review, we will discuss the origins of reproducible research, characterize the current status of reproduciblity in public health research, and connect reproduciblity to current concerns about replicability of scientific findings. Finally, we describe a path forward for improving both the reproducibility and replicability of public health research in the future.},
	urldate = {2020-09-17},
	journal = {arXiv:2007.12210 [stat]},
	author = {Peng, Roger D. and Hicks, Stephanie C.},
	month = jul,
	year = {2020},
	note = {arXiv: 2007.12210},
	keywords = {Statistics - Other Statistics}
}

@article{peng_reproducible_2011,
	title = {Reproducible {Research} in {Computational} {Science}},
	volume = {334},
	copyright = {Copyright © 2011, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	doi = {10.1126/science.1213847},
	abstract = {Computational science has led to exciting new developments, but the nature of the work has exposed limitations in our ability to evaluate published findings. Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.},
	language = {en},
	number = {6060},
	urldate = {2016-02-05},
	journal = {Science},
	author = {Peng, Roger D.},
	month = dec,
	year = {2011},
	pmid = {22144613},
	pages = {1226--1227}
}

@article{kedron_reproducibility_2020,
	title = {Reproducibility and replicability: opportunities and challenges for geospatial research},
	volume = {0},
	issn = {1365-8816},
	shorttitle = {Reproducibility and replicability},
	url = {https://doi.org/10.1080/13658816.2020.1802032},
	doi = {10.1080/13658816.2020.1802032},
	abstract = {A cornerstone of the scientific method, the ability to reproduce and replicate the results of research has gained widespread attention across the sciences in recent years. A corresponding burst of energy into how to make research more reproducible and replicable has led to numerous innovations. This article outlines some of the opportunities for geospatial researchers to contribute to and learn from the broader reproducibility literature. We review practices developed in related disciplines to improve the reproducibility and replicability of research and outline current efforts to adapt those practices to geospatial analyses. The article then highlights the open questions, opportunities, and potential new directions in geospatial research related to R\&R. We stress that the path ahead will likely require a mixture of computational, geospatial, and behavioral research that collectively addresses the many sides of reproducibility and replicability issues.},
	number = {0},
	urldate = {2020-09-17},
	journal = {International Journal of Geographical Information Science},
	author = {Kedron, Peter and Li, Wenwen and Fotheringham, Stewart and Goodchild, Michael},
	month = aug,
	year = {2020},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/13658816.2020.1802032},
	keywords = {geographic Information Science, replicability, Reproducibility, spatial analysis},
	pages = {1--19}
}


@article{brunsdon_opening_2020,
	title = {Opening practice: supporting reproducibility and critical spatial data science},
	issn = {1435-5949},
	shorttitle = {Opening practice},
	url = {https://doi.org/10.1007/s10109-020-00334-2},
	doi = {10.1007/s10109-020-00334-2},
	abstract = {This paper reflects on a number of trends towards a more open and reproducible approach to geographic and spatial data science over recent years. In particular, it considers trends towards Big Data, and the impacts this is having on spatial data analysis and modelling. It identifies a turn in academia towards coding as a core analytic tool, and away from proprietary software tools offering ‘black boxes’ where the internal workings of the analysis are not revealed. It is argued that this closed form software is problematic and considers a number of ways in which issues identified in spatial data analysis (such as the MAUP) could be overlooked when working with closed tools, leading to problems of interpretation and possibly inappropriate actions and policies based on these. In addition, this paper considers the role that reproducible and open spatial science may play in such an approach, taking into account the issues raised. It highlights the dangers of failing to account for the geographical properties of data, now that all data are spatial (they are collected somewhere), the problems of a desire for \$\$n\$\$n = all observations in data science and it identifies the need for a critical approach. This is one in which openness, transparency, sharing and reproducibility provide a mantra for defensible and robust spatial data science.},
	language = {en},
	urldate = {2020-09-17},
	journal = {Journal of Geographical Systems},
	author = {Brunsdon, Chris and Comber, Alexis},
	month = aug,
	year = {2020}
}

@article{stagge_assessing_2019,
	title = {Assessing data availability and research reproducibility in hydrology and water resources},
	volume = {6},
	copyright = {2019 The Author(s)},
	issn = {2052-4463},
	doi = {10.1038/sdata.2019.30},
	abstract = {There is broad interest to improve the reproducibility of published research. We developed a survey tool to assess the availability of digital research artifacts published alongside peer-reviewed journal articles (e.g. data, models, code, directions for use) and reproducibility of article results. We used the tool to assess 360 of the 1,989 articles published by six hydrology and water resources journals in 2017. Like studies from other fields, we reproduced results for only a small fraction of articles (1.6\% of tested articles) using their available artifacts. We estimated, with 95\% confidence, that results might be reproduced for only 0.6\% to 6.8\% of all 1,989 articles. Unlike prior studies, the survey tool identified key bottlenecks to making work more reproducible. Bottlenecks include: only some digital artifacts available (44\% of articles), no directions (89\%), or all artifacts available but results not reproducible (5\%). The tool (or extensions) can help authors, journals, funders, and institutions to self-assess manuscripts, provide feedback to improve reproducibility, and recognize and reward reproducible articles as examples for others.},
	language = {en},
	number = {1},
	urldate = {2020-09-17},
	journal = {Scientific Data},
	author = {Stagge, James H. and Rosenberg, David E. and Abdallah, Adel M. and Akbar, Hadia and Attallah, Nour A. and James, Ryan},
	month = feb,
	year = {2019},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {190030}
}

@article{stark_2018, 
  title={Before reproducibility must come preproducibility}, 
  volume={557}, 
  url={http://dx.doi.org/10.1038/d41586-018-05256-0}, 
  DOI={10.1038/d41586-018-05256-0}, 
  number={7707}, 
  journal={Nature}, 
  publisher={Springer Science and Business Media LLC}, 
  author={Stark, Philip B.}, 
  year={2018}, 
  month={May}, 
  pages={613–613} 
}
